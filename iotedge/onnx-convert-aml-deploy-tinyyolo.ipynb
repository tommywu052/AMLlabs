{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/deployment/onnx/onnx-convert-aml-deploy-tinyyolo.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO Real-time Object Detection using ONNX on AzureML\n",
        "\n",
        "This example shows how to convert the TinyYOLO model from CoreML to ONNX and operationalize it as a web service using Azure Machine Learning services and the ONNX Runtime.\n",
        "\n",
        "## What is ONNX\n",
        "ONNX is an open format for representing machine learning and deep learning models. ONNX enables open and interoperable AI by enabling data scientists and developers to use the tools of their choice without worrying about lock-in and flexibility to deploy to a variety of platforms. ONNX is developed and supported by a community of partners including Microsoft, Facebook, and Amazon. For more information, explore the [ONNX website](http://onnx.ai).\n",
        "\n",
        "## YOLO Details\n",
        "You Only Look Once (YOLO) is a state-of-the-art, real-time object detection system. For more information about YOLO, please visit the [YOLO website](https://pjreddie.com/darknet/yolo/)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "To make the best use of your time, make sure you have done the following:\n",
        "\n",
        "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
        "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration](../../../configuration.ipynb) notebook to:\n",
        "    * install the AML SDK\n",
        "    * create a workspace and its configuration file (config.json)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.20.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1612379240987
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install necessary packages\n",
        "\n",
        "You'll need to run the following commands to use this tutorial:\n",
        "\n",
        "```sh\n",
        "pip install onnxmltools\n",
        "pip install coremltools  # use this on Linux and Mac\n",
        "pip install git+https://github.com/apple/coremltools  # use this on Windows\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert model to ONNX\n",
        "\n",
        "First we download the CoreML model. We use the CoreML model from [Matthijs Hollemans's tutorial](https://github.com/hollance/YOLO-CoreML-MPSNNGraph). This may take a few minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "coreml_model_url = \"https://github.com/hollance/YOLO-CoreML-MPSNNGraph/raw/master/TinyYOLO-CoreML/TinyYOLO-CoreML/TinyYOLO.mlmodel\"\n",
        "urllib.request.urlretrieve(coreml_model_url, filename=\"TinyYOLO.mlmodel\")\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "('TinyYOLO.mlmodel', <http.client.HTTPMessage at 0x7f0f65d9cc50>)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1612379253513
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we use ONNXMLTools to convert the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxmltools\n",
        "import coremltools\n",
        "\n",
        "# Load a CoreML model\n",
        "coreml_model = coremltools.utils.load_spec('TinyYOLO.mlmodel')\n",
        "\n",
        "# Convert from CoreML into ONNX\n",
        "onnx_model = onnxmltools.convert_coreml(coreml_model, 'TinyYOLOv2')\n",
        "\n",
        "# Fix the preprocessor bias in the ImageScaler\n",
        "for init in onnx_model.graph.initializer:\n",
        "    if init.name == 'scalerPreprocessor_bias':\n",
        "        init.dims[1] = 1\n",
        "\n",
        "# Save ONNX model\n",
        "onnxmltools.utils.save_model(onnx_model, 'tinyyolov2.onnx')\n",
        "\n",
        "import os\n",
        "print(os.path.getsize('tinyyolov2.onnx'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n",
            "The maximum opset needed by this model is only 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63479035\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1612379270076
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploying as a web service with Azure ML\n",
        "\n",
        "### Load Azure ML workspace\n",
        "\n",
        "We begin by instantiating a workspace object from the existing workspace created earlier in the configuration notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.location, ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mihdemo\n",
            "eastus\n",
            "mihhol\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1612379286765
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Registering your model with Azure ML\n",
        "\n",
        "Now we upload the model and register it in the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model = Model.register(model_path = \"tinyyolov2.onnx\",\n",
        "                       model_name = \"tinyyolov2\",\n",
        "                       tags = {\"onnx\": \"demo\"},\n",
        "                       description = \"TinyYOLO\",\n",
        "                       workspace = ws)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model tinyyolov2\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1612379299329
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying your registered models\n",
        "\n",
        "You can optionally list out all the models that you have registered in this workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "models = ws.models\n",
        "for name, m in models.items():\n",
        "    print(\"Name:\", name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: best_ridge_model \tVersion: 1 \tDescription: None {}\n",
            "Name: tinyyolov2 \tVersion: 2 \tDescription: TinyYOLO {'onnx': 'demo'}\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1612379307593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write scoring file\n",
        "\n",
        "We are now going to deploy our ONNX model on Azure ML using the ONNX Runtime. We begin by writing a score.py file that will be invoked by the web service call. The `init()` function is called once when the container is started so we load the model using the ONNX Runtime into a global session object."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from azureml.core.model import Model\n",
        "import numpy as np    # we're going to use numpy to process input and output data\n",
        "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
        "\n",
        "def init():\n",
        "    global session\n",
        "    model = Model.get_model_path(model_name = 'tinyyolov2')\n",
        "    session = onnxruntime.InferenceSession(model)\n",
        "\n",
        "def preprocess(input_data_json):\n",
        "    # convert the JSON data into the tensor input\n",
        "    return np.array(json.loads(input_data_json)['data']).astype('float32')\n",
        "\n",
        "def postprocess(result):\n",
        "    return np.array(result).tolist()\n",
        "\n",
        "def run(input_data_json):\n",
        "    try:\n",
        "        start = time.time()   # start timer\n",
        "        input_data = preprocess(input_data_json)\n",
        "        input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
        "        result = session.run([], {input_name: input_data})\n",
        "        end = time.time()     # stop timer\n",
        "        return {\"result\": postprocess(result),\n",
        "                \"time\": end - start}\n",
        "    except Exception as e:\n",
        "        result = str(e)\n",
        "        return {\"error\": result}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing score.py\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up inference configuration\n",
        "First we create a YAML file that specifies which dependencies we would like to see in our container. Please note that you must include azureml-defaults with verion >= 1.0.45 as a pip dependency, because it contains the functionality needed to host the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "\n",
        "myenv = CondaDependencies.create(pip_packages=[\"numpy\", \"onnxruntime\", \"azureml-core\", \"azureml-defaults\",\"pip==20.1.1\"])\n",
        "\n",
        "with open(\"myenv.yml\",\"w\") as f:\n",
        "    f.write(myenv.serialize_to_string())"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1612381841065
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we create the inference configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "\n",
        "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1612381876784
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                               memory_gb = 1, \n",
        "                                               tags = {'demo': 'onnx'}, \n",
        "                                               description = 'web service for TinyYOLO ONNX model')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1612381881610
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will take a few minutes to run as the model gets packaged up and deployed to ACI."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "aci_service_name = 'my-aci-service-tiny-yolo'\n",
        "print(\"Service\", aci_service_name)\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Service my-aci-service-tiny-yolo\n",
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running..........................................."
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case the deployment fails, you can check the logs. Make sure to delete your aci_service before trying again."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if aci_service.state != 'Healthy':\n",
        "    # run this command for debugging.\n",
        "    print(aci_service.get_logs())\n",
        "    aci_service.delete()"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1612379954190
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Success!\n",
        "\n",
        "If you've made it this far, you've deployed a working web service that does object detection using an ONNX model. You can get the URL for the webservice with the code below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(aci_service.scoring_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://f1d1b211-ab40-4dcd-92e9-c5cb92691ae5.eastus.azurecontainer.io/score\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1612380025263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.image import ContainerImage\r\n",
        "\r\n",
        "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\r\n",
        "                                                  runtime = \"python\",\r\n",
        "                                                  conda_file = \"myenv.yml\",\r\n",
        "                                                  docker_file = \"Dockerfile\",\r\n",
        "                                                  description = \"TinyYOLO ONNX Demo\",\r\n",
        "                                                  tags = {\"demoMIH\": \"onnx\"}\r\n",
        "                                                 )\r\n",
        "\r\n",
        "\r\n",
        "image = ContainerImage.create(name = \"onnxyolo\",\r\n",
        "                              models = [model],\r\n",
        "                              image_config = image_config,\r\n",
        "                              workspace = ws)\r\n",
        "\r\n",
        "image.wait_for_creation(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: ContainerImage class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
            "  \n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Image class has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating image\n",
            "Running................................................\n",
            "Succeeded\n",
            "Image creation operation finished for image onnxyolo:5, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612382413034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(image.image_location)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mihdemo.azurecr.io/onnxyolo:5\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612382421444
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import Webservice\r\n",
        "from random import randint\r\n",
        "\r\n",
        "aci_service_name = 'onnx-tinyyolo'+str(randint(0,100))\r\n",
        "print(\"Service\", aci_service_name)\r\n",
        "\r\n",
        "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\r\n",
        "                                           image = image,\r\n",
        "                                           name = aci_service_name,\r\n",
        "                                           workspace = ws)\r\n",
        "\r\n",
        "aci_service.wait_for_deployment(True)\r\n",
        "print(aci_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Service onnx-tinyyolo99\n",
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running.......................................................................................\n",
            "Failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: deploy_from_image has been deprecated and will be removed in a future release. Please migrate to using Environments. https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: a637ea80-ab6b-4694-a47c-f93a33dc1b83\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: a637ea80-ab6b-4694-a47c-f93a33dc1b83\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: a637ea80-ab6b-4694-a47c-f93a33dc1b83\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d427741acd4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            workspace = ws)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 915\u001b[0;31m                                                       logs_response, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    916\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    917\u001b[0m                                                                                   operation_state))\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: a637ea80-ab6b-4694-a47c-f93a33dc1b83\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: a637ea80-ab6b-4694-a47c-f93a33dc1b83\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, ModuleNotFoundError: No module named 'ruamel', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az extension add --name azure-iot"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K - Downloading ..\r\u001b[K - Installing ..\r\u001b[0m"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!az login"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az account set --subscription \"Microsoft Azure Internal Consumption\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push the deployment JSON to the IOT Hub\r\n",
        "!az iot edge set-modules --device-id edgevm --hub-name a9dmhub --content deployment-iotedgeaml.json"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\r\n",
            "  {\r\n",
            "    \"authentication\": {\r\n",
            "      \"symmetricKey\": {\r\n",
            "        \"primaryKey\": \"LIZcMzyZtNuKHdVWSEggp9X1bSuQQCpQgD8lkGHNCow=\",\r\n",
            "        \"secondaryKey\": \"CW3JZ9WZuTYX6a6TdIy56EvLBJgVFI89Ra88FF1Ugt8=\"\r\n",
            "      },\r\n",
            "      \"type\": \"sas\",\r\n",
            "      \"x509Thumbprint\": {\r\n",
            "        \"primaryThumbprint\": null,\r\n",
            "        \"secondaryThumbprint\": null\r\n",
            "      }\r\n",
            "    },\r\n",
            "    \"cloudToDeviceMessageCount\": 0,\r\n",
            "    \"connectionState\": \"Disconnected\",\r\n",
            "    \"connectionStateUpdatedTime\": \"0001-01-01T00:00:00+00:00\",\r\n",
            "    \"deviceId\": \"edgevm\",\r\n",
            "    \"etag\": \"MzQ2NTg0NzA4\",\r\n",
            "    \"generationId\": \"637479303933244018\",\r\n",
            "    \"lastActivityTime\": \"0001-01-01T00:00:00+00:00\",\r\n",
            "    \"managedBy\": null,\r\n",
            "    \"moduleId\": \"$edgeAgent\"\r\n",
            "  },\r\n",
            "  {\r\n",
            "    \"authentication\": {\r\n",
            "      \"symmetricKey\": {\r\n",
            "        \"primaryKey\": null,\r\n",
            "        \"secondaryKey\": null\r\n",
            "      },\r\n",
            "      \"type\": \"none\",\r\n",
            "      \"x509Thumbprint\": {\r\n",
            "        \"primaryThumbprint\": null,\r\n",
            "        \"secondaryThumbprint\": null\r\n",
            "      }\r\n",
            "    },\r\n",
            "    \"cloudToDeviceMessageCount\": 0,\r\n",
            "    \"connectionState\": \"Disconnected\",\r\n",
            "    \"connectionStateUpdatedTime\": \"0001-01-01T00:00:00+00:00\",\r\n",
            "    \"deviceId\": \"edgevm\",\r\n",
            "    \"etag\": \"MzQ2NTg0NzA3\",\r\n",
            "    \"generationId\": \"637479303933244018\",\r\n",
            "    \"lastActivityTime\": \"0001-01-01T00:00:00+00:00\",\r\n",
            "    \"managedBy\": \"iotEdge\",\r\n",
            "    \"moduleId\": \"$edgeHub\"\r\n",
            "  }\r\n",
            "]\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612383659533
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you are eventually done using the web service, remember to delete it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "aci_service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "index_order": 5,
    "exclude_from_index": false,
    "task": "Object Detection",
    "deployment": [
      "Azure Container Instance"
    ],
    "authors": [
      {
        "name": "viswamy"
      }
    ],
    "star_tag": [
      "featured"
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "local"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "tags": [
      "ONNX Converter"
    ],
    "datasets": [
      "PASCAL VOC"
    ],
    "categories": [
      "how-to-use-azureml",
      "deployment",
      "onnx"
    ],
    "category": "deployment",
    "framework": [
      "ONNX"
    ],
    "friendly_name": "Convert and deploy TinyYolo with ONNX Runtime",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}